{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qartmp/.conda/envs/TSAD/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import shutil\n",
    "import argparse\n",
    "import configparser\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.sparse.linalg import eigs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.nn.utils import weight_norm\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxnormalization(train, test ,_max ,_min):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def normalize(x):\n",
    "        x = 1. * (x - _min) / (_max - _min)\n",
    "        x = 2. * x - 1.\n",
    "        return x\n",
    "\n",
    "    train_norm = normalize(train)\n",
    "    test_norm = normalize(test)\n",
    "\n",
    "    return train_norm,test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(root, param):\n",
    "    dict_table = []\n",
    "    X_train = pd.read_csv(root+\"_\"+param+\".csv\")\n",
    "    Y = torch.from_numpy(X_train[\"Label\"].values)\n",
    "    for v in X_train.drop([\"Label\"],axis = 1).values:\n",
    "        table = []\n",
    "        table.append(list(v))\n",
    "        dict_table.append(table)\n",
    "    X = torch.Tensor(dict_table) \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/sdb/Dataset/QarBigData/HKY/2023/B737/ALT_STDC.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3939247/2411235308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# 读取CSV文件为DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# 获取列数减2（忽略\"Time\"和\"Label\"列）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TSAD/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/sdb/Dataset/QarBigData/HKY/2023/B737/ALT_STDC.csv'"
     ]
    }
   ],
   "source": [
    "# 定义数据根目录\n",
    "root = \"/mnt/sdb/Dataset/QarBigData/HKY/2023/B737/\" #波音737数据集文件位置\n",
    "\n",
    "# 定义用于存储不同采样频率的数据列表\n",
    "X_1HZ, X_2HZ, X_4HZ, X_8HZ, Y = [], [], [], [], []\n",
    "select = 30  # 选择的时间步数，用于截取每个参数的前 'select' 个时间步\n",
    "\n",
    "# 定义A320参数列表（飞行相关参数的名称）\n",
    "# param_list = ['WIN_ALG', 'WIN_CRS', 'IAS', 'GS', 'VAPP', 'N11', 'N12', 'TLA1', 'TLA2', \n",
    "#               'DME1', 'DME2', 'FLAP_PL', 'FLAP_PR', 'LDGL', 'LDGR', 'LDGNOS', \n",
    "#               'ALT_QNH', 'ALT_STD', 'RADIO_LH', 'RADIO_RH', 'IVV', 'ROLL', \n",
    "#               'ROLL_CMD', 'PITCH', 'PITCH_CMD', 'GW', 'RUDD']\n",
    "# 定义B737参数列表\n",
    "param_list = [\n",
    "    'ALT_STDC',    # 校正标准高度（Standard Altitude Corrected)\n",
    "    'GS',          # 地速（Ground Speed）\n",
    "    'N11',         # 左发动机转速（低压转子转速 N1 for Engine 1）\n",
    "    'N12',         # 右发动机转速（低压转子转速 N1 for Engine 2）\n",
    "    'TLA1',        # 左侧油门杆位置（Throttle Lever Angle for Engine 1）\n",
    "    'TLA2',        # 右侧油门杆位置（Throttle Lever Angle for Engine 2）\n",
    "    'GWC',         # 校正后的飞机总重（Calibrated Gross Weight）\n",
    "    'IVV_R',       # 原始垂直速度（Raw Vertical Velocity）\n",
    "    'WIN_CRS',     # 风的航向角（Wind Course Angle）\n",
    "    'WIN_ALG',     # 风的倾斜角（Wind Angle of Lean）\n",
    "    'RALT1',       # 左侧无线电高度（Radio Altitude - Left Hand）\n",
    "    'RALT2',       # 右侧无线电高度（Radio Altitude - Right Hand）\n",
    "    'PITCH',       # 俯仰角（Pitch Angle）\n",
    "    'IAS',         # 指示空速（Indicated Airspeed）\n",
    "    'ROLL',        # 横滚角（Roll Angle）\n",
    "    'VRTG',        # 垂直G力（Vertical Load Factor）\n",
    "    'RUDD',        # 方向舵位置（Rudder Position）\n",
    "    'PITCH_CMD',   # 指令俯仰角（Commanded Pitch Angle）\n",
    "    'ROLL_CMD'     # 指令横滚角（Commanded Roll Angle）\n",
    "]\n",
    "\n",
    "# 定义存储不同频率的参数名称列表\n",
    "param_list_1HZ, param_list_2HZ, param_list_4HZ, param_list_8HZ = [], [], [], []\n",
    "\n",
    "# 遍历每个参数，从各自的CSV文件中读取数据\n",
    "for param in param_list:\n",
    "    # 读取CSV文件为DataFrame\n",
    "    df = pd.read_csv(root + param + \".csv\")\n",
    "    l = len(df.columns.tolist()) - 2  # 获取列数减2（忽略\"Time\"和\"Label\"列）\n",
    "    \n",
    "    # 将标签列（\"Label\"）转为torch张量\n",
    "    Y = torch.from_numpy(df[\"Label\"].values)\n",
    "    \n",
    "    # 创建存储数据的列表，跳过\"Time\"和\"Label\"列\n",
    "    dict_table = []\n",
    "    for i in df.drop([\"Time\", \"Label\"], axis=1).values:\n",
    "        table = []\n",
    "        table.append(list(i))  # 将每行数据转换为列表\n",
    "        dict_table.append(table)\n",
    "    \n",
    "    # 将dict_table转换为torch张量\n",
    "    X = torch.Tensor(dict_table)\n",
    "    \n",
    "    # 根据采样频率将数据划分到不同列表，并截取前 's' 个时间步的数据\n",
    "    if X.shape[2] == 50:  # 1Hz采样频率\n",
    "        s = select  # 保留的时间步数\n",
    "        X_1HZ.append(X[:, :, 0:s])\n",
    "        param_list_1HZ.append(param)\n",
    "    elif X.shape[2] == 100:  # 2Hz采样频率\n",
    "        s = select * 2  # 保留的时间步数\n",
    "        X_2HZ.append(X[:, :, 0:s])\n",
    "        param_list_2HZ.append(param)\n",
    "    elif X.shape[2] == 200:  # 4Hz采样频率\n",
    "        s = select * 4  # 保留的时间步数\n",
    "        X_4HZ.append(X[:, :, 0:s])\n",
    "        param_list_4HZ.append(param)\n",
    "    else:  # 假定其他为8Hz采样频率\n",
    "        s = select * 8  # 保留的时间步数\n",
    "        X_8HZ.append(X[:, :, 0:s])\n",
    "        param_list_8HZ.append(param)\n",
    "\n",
    "# 将每种频率的数据列表合并成一个张量，按维度1（列方向）进行拼接\n",
    "X_1HZ_tensor = torch.cat(X_1HZ, dim=1)\n",
    "X_2HZ_tensor = torch.cat(X_2HZ, dim=1)\n",
    "X_4HZ_tensor = torch.cat(X_4HZ, dim=1)\n",
    "X_8HZ_tensor = torch.cat(X_8HZ, dim=1)\n",
    "\n",
    "X_8HZ_tensor=torch.cat(X_8HZ, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_line = int(len(Y) * 0.7) #训练集:测试集=7:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_1HZ_tensor=X_1HZ_tensor[:split_line]\n",
    "train_X_2HZ_tensor=X_2HZ_tensor[:split_line]\n",
    "train_X_4HZ_tensor=X_4HZ_tensor[:split_line]\n",
    "train_X_8HZ_tensor=X_8HZ_tensor[:split_line]\n",
    "train_Y_tensor=Y[:split_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_1HZ_tensor=X_1HZ_tensor[split_line:]\n",
    "test_X_2HZ_tensor=X_2HZ_tensor[split_line:]\n",
    "test_X_4HZ_tensor=X_4HZ_tensor[split_line:]\n",
    "test_X_8HZ_tensor=X_8HZ_tensor[split_line:]\n",
    "test_Y_tensor=Y[split_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_1HZ = torch.amax(train_X_1HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "min_1HZ = torch.amin(train_X_1HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "max_2HZ = torch.amax(train_X_2HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "min_2HZ = torch.amin(train_X_2HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "max_4HZ = torch.amax(train_X_4HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "min_4HZ = torch.amin(train_X_4HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "max_8HZ = torch.amax(train_X_8HZ_tensor, dim=(0, 2), keepdims=True)\n",
    "min_8HZ = torch.amin(train_X_8HZ_tensor, dim=(0, 2), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_1HZ_tensor_norm,test_X_1HZ_tensor_norm = MinMaxnormalization(train_X_1HZ_tensor, test_X_1HZ_tensor,max_1HZ,min_1HZ)\n",
    "train_X_2HZ_tensor_norm,test_X_2HZ_tensor_norm = MinMaxnormalization(train_X_2HZ_tensor, test_X_2HZ_tensor,max_2HZ,min_2HZ)\n",
    "train_X_4HZ_tensor_norm,test_X_4HZ_tensor_norm = MinMaxnormalization(train_X_4HZ_tensor, test_X_4HZ_tensor,max_4HZ,min_4HZ)\n",
    "train_X_8HZ_tensor_norm,test_X_8HZ_tensor_norm = MinMaxnormalization(train_X_8HZ_tensor, test_X_8HZ_tensor,max_8HZ,min_8HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim, dim2,dim4,dim8,dim_test = train_X_1HZ_tensor_norm.shape[0],train_X_2HZ_tensor_norm.shape[1],train_X_4HZ_tensor_norm.shape[1],train_X_8HZ_tensor_norm.shape[1],test_X_1HZ_tensor_norm.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_2HZ_tensor_norm,test_X_2HZ_tensor_norm=train_X_2HZ_tensor_norm.reshape(dim, dim2,select,2),  test_X_2HZ_tensor_norm.reshape(dim_test, dim2,select,2)\n",
    "train_X_4HZ_tensor_norm,test_X_4HZ_tensor_norm=train_X_4HZ_tensor_norm.reshape(dim, dim4,select,4),  test_X_4HZ_tensor_norm.reshape(dim_test, dim4,select,4)\n",
    "train_X_8HZ_tensor_norm,test_X_8HZ_tensor_norm=train_X_8HZ_tensor_norm.reshape(dim, dim8,select,8),  test_X_8HZ_tensor_norm.reshape(dim_test, dim8,select,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_2HZ_tensor_norm,test_X_2HZ_tensor_norm=train_X_2HZ_tensor.reshape(dim, dim2,select,2),  test_X_2HZ_tensor.reshape(dim_test, dim2,select,2)\n",
    "train_X_4HZ_tensor_norm,test_X_4HZ_tensor_norm=train_X_4HZ_tensor.reshape(dim, dim4,select,4),  test_X_4HZ_tensor.reshape(dim_test, dim4,select,4)\n",
    "train_X_8HZ_tensor_norm,test_X_8HZ_tensor_norm=train_X_8HZ_tensor.reshape(dim, dim8,select,8),  test_X_8HZ_tensor.reshape(dim_test, dim8,select,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_X_1HZ_tensor_norm,train_X_2HZ_tensor_norm, train_X_4HZ_tensor_norm,train_X_8HZ_tensor_norm,train_Y_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_X_1HZ_tensor_norm,test_X_2HZ_tensor_norm, test_X_4HZ_tensor_norm,test_X_8HZ_tensor_norm,test_Y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集上采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = torch.where(train_Y_tensor == 0)[0]\n",
    "indices_1 = torch.where(train_Y_tensor == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_1_upsampled = resample(indices_1, replace=True, n_samples=len(indices_0), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_indices = torch.cat([indices_0, indices_1_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_1HZ_tensor_norm_balanced = train_X_1HZ_tensor_norm[balanced_indices]\n",
    "train_X_2HZ_tensor_norm_balanced = train_X_2HZ_tensor_norm[balanced_indices]\n",
    "train_X_4HZ_tensor_norm_balanced = train_X_4HZ_tensor_norm[balanced_indices]\n",
    "train_X_8HZ_tensor_norm_balanced = train_X_8HZ_tensor_norm[balanced_indices]\n",
    "train_Y_tensor_balanced = train_Y_tensor[balanced_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = torch.randperm(len(train_Y_tensor_balanced))\n",
    "train_X_1HZ_tensor_norm_balanced = train_X_1HZ_tensor_norm_balanced[shuffled_indices]\n",
    "train_X_2HZ_tensor_norm_balanced = train_X_2HZ_tensor_norm_balanced[shuffled_indices]\n",
    "train_X_4HZ_tensor_norm_balanced = train_X_4HZ_tensor_norm_balanced[shuffled_indices]\n",
    "train_X_8HZ_tensor_norm_balanced = train_X_8HZ_tensor_norm_balanced[shuffled_indices]\n",
    "train_Y_tensor_balanced = train_Y_tensor_balanced[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_X_1HZ_tensor_norm_balanced, \n",
    "    train_X_2HZ_tensor_norm_balanced, \n",
    "    train_X_4HZ_tensor_norm_balanced, \n",
    "    train_X_8HZ_tensor_norm_balanced, \n",
    "    train_Y_tensor_balanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.conv2, self.chomp2, self.dropout1)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_HZ, hidden_size):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 更新门的权重和偏置\n",
    "        self.W_z = nn.Linear(input_HZ, hidden_size)\n",
    "        self.U_z = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # 重置门的权重和偏置\n",
    "        self.W_r = nn.Linear(input_HZ, hidden_size)\n",
    "        self.U_r = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # 候选隐藏状态的权重和偏置\n",
    "        self.W_h = nn.Linear(input_HZ, hidden_size)\n",
    "        self.U_h = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # 更新门 z_t\n",
    "        z_t = torch.sigmoid(self.W_z(x) + self.U_z(h))\n",
    "        \n",
    "        # 重置门 r_t\n",
    "        r_t = torch.sigmoid(self.W_r(x) + self.U_r(h))\n",
    "        \n",
    "        # 候选隐藏状态 h_tilda\n",
    "        h_tilda = torch.tanh(self.W_h(x) + self.U_h(r_t * h))\n",
    "        \n",
    "        # 当前隐藏状态 h_t\n",
    "        h_t = (1 - z_t) * h + z_t * h_tilda\n",
    "        \n",
    "        return h_t\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_HZ, hidden_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_cell = nn.GRUCell(input_HZ, hidden_size)\n",
    "        self.linear=nn.Linear(hidden_size,input_HZ)\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        \"\"\"\n",
    "        :param x: 输入序列，形状为 (batch_size, HZ, seq_len)\n",
    "        :param h0: 初始隐藏状态，形状为 (batch_size, hidden_size)\n",
    "        :return: 最后的隐藏状态和输出序列\n",
    "        \"\"\"\n",
    "        batch_size, _, seq_len = x.size()\n",
    "        \n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        h_t = h0\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, :, t]\n",
    "            h_t = self.gru_cell(x_t, h_t)\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "#         h_tt=self.linear(h_t)\n",
    "        return outputs, h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMVTCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMVTCN(nn.Module):\n",
    "    def __init__(self, param_sizes, input_size, time_output_size, output_size, num_channels, kernel_size, dropout, num_1HZ,num_2HZ,num_4HZ,num_8HZ,time_forward= 0, imbalance_data = False, isDiffKernel = False, gap = False, out_middle_layer = False, out_path = \"\" ):\n",
    "        super(IMVTCN, self).__init__()\n",
    "        parallel_net1,parallel_net2,parallel_net4,parallel_net8 = [],[],[],[]\n",
    "        parallel_linear1,parallel_linear2,parallel_linear4,parallel_linear8 = [],[],[],[]\n",
    "        self.minsize = np.min(param_sizes)-1\n",
    "        self.num_1HZ=num_1HZ\n",
    "        self.num_2HZ=num_2HZ\n",
    "        self.num_4HZ=num_4HZ\n",
    "        self.num_8HZ=num_8HZ\n",
    "        parallel_gru1,parallel_gru2,parallel_gru4,parallel_gru8 = [], [], [], []\n",
    "        for i in range(num_1HZ):\n",
    "            parallel_gru1 += [nn.Linear(param_sizes,30)]\n",
    "        for i in range(num_2HZ):\n",
    "            parallel_gru2 += [GRU(param_sizes,30)]\n",
    "        for i in range(num_4HZ):\n",
    "            parallel_gru4 += [GRU(param_sizes,30)]\n",
    "        for i in range(num_8HZ):\n",
    "            parallel_gru8 += [GRU(param_sizes,30)]\n",
    "            \n",
    "            \n",
    "        for i in range(num_1HZ):\n",
    "            parallel_net1 += [nn.Linear(1*50,30)]\n",
    "            parallel_linear1 += [nn.Linear(num_channels[-1], time_output_size)]\n",
    "        for i in range(num_2HZ):\n",
    "            parallel_net2 += [nn.Linear(2*50,30)]\n",
    "            parallel_linear2 += [nn.Linear(num_channels[-1], time_output_size)]\n",
    "        for i in range(num_4HZ):\n",
    "            parallel_net4 += [nn.Linear(4*50,30)]\n",
    "            parallel_linear4 += [nn.Linear(num_channels[-1], time_output_size)]\n",
    "        for i in range(num_8HZ):\n",
    "            parallel_net8 += [nn.Linear(8*50,30)]\n",
    "            parallel_linear8 += [nn.Linear(num_channels[-1], time_output_size)]\n",
    "        self.dtimef = time_forward\n",
    "        self.gap = gap\n",
    "        self.im = imbalance_data\n",
    "        self.oml = out_middle_layer\n",
    "        if self.oml: self.out_path = out_path\n",
    "        self.net1 = nn.ModuleList(parallel_gru1)\n",
    "        self.net2 = nn.ModuleList(parallel_gru2)\n",
    "        self.net4 = nn.ModuleList(parallel_gru4)\n",
    "        self.net8 = nn.ModuleList(parallel_gru8)\n",
    "        self.linear1 = nn.ModuleList(parallel_linear1)\n",
    "        self.linear2 = nn.ModuleList(parallel_linear2)\n",
    "        self.linear4 = nn.ModuleList(parallel_linear4)\n",
    "        self.linear8 = nn.ModuleList(parallel_linear8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(time_output_size*(num_1HZ+num_2HZ+num_4HZ+num_8HZ),output_size)\n",
    "    \n",
    "#     def mkdir(self,path):\n",
    "#         path=path.strip()\n",
    "#         path=path.rstrip(\"\\\\\")\n",
    "#         path=path.rstrip(\"/\")\n",
    "#         isExists=os.path.exists(path)\n",
    "#         if not isExists:\n",
    "#             os.makedirs(path) \n",
    "            \n",
    "    def select_data(self, time, ys):\n",
    "        y_list = []\n",
    "        for i in range(len(ys)):\n",
    "            y = ys[i]\n",
    "            ti = int(time[i][0].item()) \n",
    "            t = ti-1 if (ti!=0) and (ti%self.minsize==0) else ti\n",
    "            t = int(t - self.dtimef*(y.shape[1]/self.minsize))\n",
    "            if self.im:\n",
    "                if self.gap:\n",
    "                    sl = torch.mean(y[:,:t+1],1)\n",
    "                else:\n",
    "                    sl = y[:,t]\n",
    "            else:\n",
    "                if self.gap:\n",
    "                    sl = torch.mean(y[:,:t+1],1).cpu().detach().numpy().tolist()\n",
    "                else:\n",
    "                    sl = y[:,t].cpu().detach().numpy().tolist()\n",
    "            y_list.append(sl)\n",
    "        if self.im: return torch.stack(y_list,0).view(len(y_list),-1)\n",
    "        else: return Variable(torch.Tensor(y_list).cuda())\n",
    "\n",
    "    def forward(self, X_1HZ,X_2HZ,X_4HZ,X_8HZ):\n",
    "        \"\"\"(batch_size, num_2HZ, 50, 2)\"\"\"\n",
    "        out_list = []\n",
    "        start_point = 0\n",
    "        batch_size=X_1HZ.shape[0]\n",
    "        for i,net in enumerate(self.net1):\n",
    "            y1 = net(X_1HZ[:,i,:])\n",
    "            o = self.linear1[i](y1)\n",
    "            out_list.append(o)\n",
    "        for i,net in enumerate(self.net2):\n",
    "            y2 = net(X_2HZ[:,i,:,:])[1]\n",
    "            self.linear2[i](y2)\n",
    "            out_list.append(o)\n",
    "        for i,net in enumerate(self.net4):\n",
    "            y4 = net(X_4HZ[:,i,:,:])[1]\n",
    "            o = self.linear4[i](y4)\n",
    "            out_list.append(o)\n",
    "        for i,net in enumerate(self.net8):\n",
    "            y8 = net(X_8HZ[:,i,:,:])[1]\n",
    "            o = self.linear8[i](y8)\n",
    "            out_list.append(o)\n",
    "        cat_feature = torch.cat((out_list), dim = 1)\n",
    "        out = self.linear(cat_feature)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for i,net in enumerate(self.net):\n",
    "#             y1 = net(inputs[:,:,start_point:start_point+param_sizes[i]-1]).squeeze(1)\n",
    "# #             time = inputs[:,:,start_point+param_sizes[i]-1]\n",
    "# #             start_point += param_sizes[i]\n",
    "# #             activ = self.relu(y1)\n",
    "# #             device = torch.cuda.current_device()\n",
    "# #             if self.oml:\n",
    "# #                 active = activ.cpu().detach().numpy()\n",
    "# #                 path = self.out_path+\"time_forward\"+str(self.dtimef)+\"/activation/\"+str(start_point)+\"/\"+str(device)+\"/\"\n",
    "# #                 self.mkdir(path)\n",
    "# #                 np.savez(path+str(batch)+'.npz',active)\n",
    "# #             sd = self.select_data(time,activ)\n",
    "#             o = self.linear1[i](y1)\n",
    "#             out_list.append(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#设置param_sizes、namelist\n",
    "param_sizes = [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, \n",
    "               201, 201, 201, 51, 51, 201, 201, 51, 101, 401, 201, 401, 51, 101]\n",
    "namelist = ['WIN_ALG','WIN_CRS','IAS','GS','VAPP','N11','N12','TLA1','TLA2','DME1','DME2','FLAP_PL','FLAP_PR',\n",
    "              'LDGL','LDGR','LDGNOS','ALT_QNH','ALT_STD','RADIO_LH','RADIO_RH',\n",
    "              'IVV','ROLL','ROLL_CMD','PITCH','PITCH_CMD','GW','RUDD']\n",
    "# base = \"./data/A320/origin/\"\n",
    "# param_sizes = []\n",
    "# for p in namelist:\n",
    "#     df = pd.read_csv(base+p+\".csv\")\n",
    "#     l = len(df.columns.tolist())-1\n",
    "#     print(p,l)\n",
    "#     param_sizes.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 75 #服务器ID，76时并行多块GPU运行\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "input_channels = 1  #输入通道 1\n",
    "time_output_size = 1 #实验点 动态调整 每个参数几个特征表示 1 2 3 4\n",
    "n_classes = 2   # 输出 2分类问题\n",
    "layers = 3 # 动态调整 层数 3 4 5 6\n",
    "nhid = 30 #隐藏层个数\n",
    "channel_sizes = [nhid]*layers\n",
    "kernel_size = 5 # 动态调整 卷积核尺度 3 5 7 9\n",
    "dropout = 0.5 # 根据需求调整 0.5 0.2 0.05\n",
    "time_forward = 0 # 动态调整 选取时间点 取0时：VRTG峰值或完成接地时刻  0 2 4\n",
    "imbalance_data = True\n",
    "imrate = 133.55 # 样本的比例\n",
    "isDiffKernel = False  # 动态调整 是否每个子模型卷积核不相同\n",
    "gap = False # 动态调整 是否用全局平均池化\n",
    "out_middle_layer = False #是否输出模型中间产生数据 要求time_forward = 0, time_output_size = 1时输出，最后一次迭代\n",
    "out_path = \"/home/qartmp/Project/Jupyter/LiCX/\"\n",
    "model_save = \"./data/A320/result/\" # 存储训练好的模型\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "parser = argparse.ArgumentParser(description='Sequence Modeling - Safety incidents')\n",
    "parser.add_argument('--cuda', action='store_false',\n",
    "                    help='use CUDA (default: True)')\n",
    "parser.add_argument('--clip', type=float, default=-1,\n",
    "                    help='gradient clip, -1 means no clip (default: -1)')\n",
    "parser.add_argument('--log-interval', type=int, default=25, metavar='N',\n",
    "                    help='report interval (default: 100')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed (default: 1111)')\n",
    "parser.add_argument('--lr', type=float, default=1e-2,\n",
    "                    help='initial learning rate (default: 1e-2)')\n",
    "parser.add_argument('--optim', type=str, default='Adam',\n",
    "                    help='optimizer to use (default: Adam)')\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "if imbalance_data:\n",
    "    loss_func = nn.CrossEntropyLoss(weight = torch.tensor([1,imrate],device = 'cuda'))\n",
    "else:\n",
    "    loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMVTCN(select,input_channels, time_output_size, \n",
    "                   n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout,num_1HZ=len(param_list_1HZ),num_2HZ=len(param_list_2HZ),num_4HZ=len(param_list_4HZ),num_8HZ=len(param_list_8HZ),\n",
    "                  time_forward= time_forward, imbalance_data = imbalance_data, \n",
    "                   isDiffKernel = isDiffKernel, gap = gap,\n",
    "                   out_middle_layer = out_middle_layer, out_path = out_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    path=path.strip()\n",
    "    path=path.rstrip(\"\\\\\")\n",
    "    path=path.rstrip(\"/\")\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def train(train_loader, model,epoch):\n",
    "    global lr,steps\n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    train_loss = 0\n",
    "    steps = 0\n",
    "    correct,tp,tn,fn,fp = 0,0,0,0,0\n",
    "    for batch_index, batch_data in enumerate(train_loader):\n",
    "        batch_size = batch_data[0].shape[0]\n",
    "        num_1HZ = batch_data[0].shape[1]\n",
    "        num_2HZ = batch_data[1].shape[1]\n",
    "        num_4HZ = batch_data[2].shape[1]\n",
    "        num_8HZ = batch_data[3].shape[1]\n",
    "        input_1HZ = batch_data[0].cuda()\n",
    "        input_2HZ = batch_data[1].reshape(batch_size, num_2HZ, select, 2).cuda()\n",
    "        input_4HZ = batch_data[2].reshape(batch_size, num_4HZ, select, 4).cuda()\n",
    "        input_8HZ = batch_data[3].reshape(batch_size, num_8HZ, select, 8).cuda()\n",
    "        y = batch_data[4].cuda()\n",
    "        input_1HZ,input_2HZ,input_4HZ,input_8HZ, y = Variable(input_1HZ),Variable(input_2HZ),Variable(input_4HZ),Variable(input_8HZ), Variable(y)\n",
    "        seq_length = batch_size\n",
    "        optimizer.zero_grad()\n",
    "        device = torch.cuda.current_device()\n",
    "        output = model(input_1HZ,input_2HZ,input_4HZ,input_8HZ)\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()    \n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss = loss.item()\n",
    "        batch_idx += 1\n",
    "        train_loss += training_loss * batch_size\n",
    "        steps += batch_size\n",
    "        \n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "#         if out_middle_layer:\n",
    "#             ocdn,ycdn,pcdn = output.cpu().detach().numpy(),y.cpu().detach().numpy(),pred.data.view_as(y.data).cpu().detach().numpy()\n",
    "#             path = out_path+'/time_limit'+str(time_forward)+'/label_result/'+str(device)+'/' \n",
    "#             mkdir(path)\n",
    "#             np.savez(path+'train_'+str(i)+'.npz',pro=ocdn,real=ycdn,predict=pcdn)\n",
    "        correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "        tp += ((pred.data.view_as(y.data) == 1)&(y.data == 1)).cpu().sum()\n",
    "        tn += ((pred.data.view_as(y.data) == 0)&(y.data == 0)).cpu().sum()\n",
    "        fn += ((pred.data.view_as(y.data) == 0)&(y.data == 1)).cpu().sum()\n",
    "        fp += ((pred.data.view_as(y.data) == 1)&(y.data == 0)).cpu().sum()\n",
    "    train_loss = train_loss / steps\n",
    "    accuracy = correct / steps \n",
    "    p = tp.item() / (tp.item() + fp.item())\n",
    "    r = tp.item() / (tp.item() + fn.item())\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    # 打印训练和验证指标\n",
    "    print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
    "      f'Train Precision: {tp}/{tp + fp} ({100. * p:.0f}%), '\n",
    "      f'Train Recall: {tp}/{tp + fn} ({100. * r:.0f}%), '\n",
    "      f'Train F1: {100. * F1:.0f}%'\n",
    "      )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def test(test_loader, model,epoch):\n",
    "    global lr,steps\n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    train_loss = 0\n",
    "    steps = 0\n",
    "    correct,tp,tn,fn,fp = 0,0,0,0,0\n",
    "    for batch_index, batch_data in enumerate(test_loader):\n",
    "        batch_size = batch_data[0].shape[0]\n",
    "        num_1HZ = batch_data[0].shape[1]\n",
    "        num_2HZ = batch_data[1].shape[1]\n",
    "        num_4HZ = batch_data[2].shape[1]\n",
    "        num_8HZ = batch_data[3].shape[1]\n",
    "        input_1HZ = batch_data[0].cuda()\n",
    "        input_2HZ = batch_data[1].reshape(batch_size, num_2HZ, select, 2).cuda()\n",
    "        input_4HZ = batch_data[2].reshape(batch_size, num_4HZ, select, 4).cuda()\n",
    "        input_8HZ = batch_data[3].reshape(batch_size, num_8HZ, select, 8).cuda()\n",
    "        y = batch_data[4].cuda()\n",
    "        input_1HZ,input_2HZ,input_4HZ,input_8HZ, y = Variable(input_1HZ),Variable(input_2HZ),Variable(input_4HZ),Variable(input_8HZ), Variable(y)\n",
    "        seq_length = batch_size\n",
    "        optimizer.zero_grad()\n",
    "        device = torch.cuda.current_device()\n",
    "        output = model(input_1HZ,input_2HZ,input_4HZ,input_8HZ)\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()    \n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss = loss.item()\n",
    "        batch_idx += 1\n",
    "        train_loss += training_loss * batch_size\n",
    "        steps += batch_size\n",
    "        \n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "#         if out_middle_layer:\n",
    "#             ocdn,ycdn,pcdn = output.cpu().detach().numpy(),y.cpu().detach().numpy(),pred.data.view_as(y.data).cpu().detach().numpy()\n",
    "#             path = out_path+'/time_limit'+str(time_forward)+'/label_result/'+str(device)+'/' \n",
    "#             mkdir(path)\n",
    "#             np.savez(path+'train_'+str(i)+'.npz',pro=ocdn,real=ycdn,predict=pcdn)\n",
    "        correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "        tp += ((pred.data.view_as(y.data) == 1)&(y.data == 1)).cpu().sum()\n",
    "        tn += ((pred.data.view_as(y.data) == 0)&(y.data == 0)).cpu().sum()\n",
    "        fn += ((pred.data.view_as(y.data) == 0)&(y.data == 1)).cpu().sum()\n",
    "        fp += ((pred.data.view_as(y.data) == 1)&(y.data == 0)).cpu().sum()\n",
    "    train_loss = train_loss / steps\n",
    "    accuracy = correct / steps \n",
    "    p = tp.item() / (tp.item() + fp.item())\n",
    "    r = tp.item() / (tp.item() + fn.item())\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    # 打印训练和验证指标\n",
    "    print(f'Epoch {epoch}, Test Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.4f}, '\n",
    "      f'Test Precision: {tp}/{tp + fp} ({100. * p:.0f}%), '\n",
    "      f'Test Recall: {tp}/{tp + fn} ({100. * r:.0f}%), '\n",
    "      f'Test F1: {100. * F1:.0f}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4351, Train Accuracy: 0.8964, Train Precision: 122/2780 (4%), Train Recall: 122/215 (57%), Train F1: 8%\n",
      "Epoch 1, Test Loss: 0.5061, Test Accuracy: 0.9283, Test Precision: 26/801 (3%), Test Recall: 26/67 (39%), Test F1: 6%\n",
      "Epoch 2, Train Loss: 0.4140, Train Accuracy: 0.8969, Train Precision: 133/2787 (5%), Train Recall: 133/215 (62%), Train F1: 9%\n",
      "Epoch 2, Test Loss: 0.4844, Test Accuracy: 0.9213, Test Precision: 23/874 (3%), Test Recall: 23/67 (34%), Test F1: 5%\n",
      "Epoch 3, Train Loss: 0.4134, Train Accuracy: 0.9033, Train Precision: 127/2606 (5%), Train Recall: 127/215 (59%), Train F1: 9%\n",
      "Epoch 3, Test Loss: 0.4492, Test Accuracy: 0.9399, Test Precision: 25/667 (4%), Test Recall: 25/67 (37%), Test F1: 7%\n",
      "Epoch 4, Train Loss: 0.3720, Train Accuracy: 0.9093, Train Precision: 135/2463 (5%), Train Recall: 135/215 (63%), Train F1: 10%\n",
      "Epoch 4, Test Loss: 0.4432, Test Accuracy: 0.9297, Test Precision: 28/789 (4%), Test Recall: 28/67 (42%), Test F1: 7%\n",
      "Epoch 5, Train Loss: 0.3562, Train Accuracy: 0.9101, Train Precision: 145/2461 (6%), Train Recall: 145/215 (67%), Train F1: 11%\n",
      "Epoch 5, Test Loss: 0.5312, Test Accuracy: 0.8895, Test Precision: 35/1260 (3%), Test Recall: 35/67 (52%), Test F1: 5%\n",
      "Epoch 6, Train Loss: 0.3227, Train Accuracy: 0.9263, Train Precision: 157/2055 (8%), Train Recall: 157/215 (73%), Train F1: 14%\n",
      "Epoch 6, Test Loss: 0.4103, Test Accuracy: 0.9375, Test Precision: 28/700 (4%), Test Recall: 28/67 (42%), Test F1: 7%\n",
      "Epoch 7, Train Loss: 0.3016, Train Accuracy: 0.9176, Train Precision: 156/2284 (7%), Train Recall: 156/215 (73%), Train F1: 12%\n",
      "Epoch 7, Test Loss: 0.3965, Test Accuracy: 0.9285, Test Precision: 30/807 (4%), Test Recall: 30/67 (45%), Test F1: 7%\n",
      "Epoch 8, Train Loss: 0.2727, Train Accuracy: 0.9326, Train Precision: 163/1900 (9%), Train Recall: 163/215 (76%), Train F1: 15%\n",
      "Epoch 8, Test Loss: 0.4314, Test Accuracy: 0.9128, Test Precision: 33/991 (3%), Test Recall: 33/67 (49%), Test F1: 6%\n",
      "Epoch 9, Train Loss: 0.2503, Train Accuracy: 0.9348, Train Precision: 169/1854 (9%), Train Recall: 169/215 (79%), Train F1: 16%\n",
      "Epoch 9, Test Loss: 0.3864, Test Accuracy: 0.9194, Test Precision: 33/916 (4%), Test Recall: 33/67 (49%), Test F1: 7%\n",
      "Epoch 10, Train Loss: 0.2676, Train Accuracy: 0.9323, Train Precision: 169/1920 (9%), Train Recall: 169/215 (79%), Train F1: 16%\n",
      "Epoch 10, Test Loss: 0.3326, Test Accuracy: 0.9351, Test Precision: 34/740 (5%), Test Recall: 34/67 (51%), Test F1: 8%\n",
      "Epoch 11, Train Loss: 0.2188, Train Accuracy: 0.9312, Train Precision: 186/1983 (9%), Train Recall: 186/215 (87%), Train F1: 17%\n",
      "Epoch 11, Test Loss: 0.2229, Test Accuracy: 0.9730, Test Precision: 41/322 (13%), Test Recall: 41/67 (61%), Test F1: 21%\n",
      "Epoch 12, Train Loss: 0.1544, Train Accuracy: 0.9587, Train Precision: 191/1263 (15%), Train Recall: 191/215 (89%), Train F1: 26%\n",
      "Epoch 12, Test Loss: 0.2074, Test Accuracy: 0.9708, Test Precision: 43/351 (12%), Test Recall: 43/67 (64%), Test F1: 21%\n",
      "Epoch 13, Train Loss: 0.1453, Train Accuracy: 0.9600, Train Precision: 199/1245 (16%), Train Recall: 199/215 (93%), Train F1: 27%\n",
      "Epoch 13, Test Loss: 0.1921, Test Accuracy: 0.9707, Test Precision: 49/364 (13%), Test Recall: 49/67 (73%), Test F1: 23%\n",
      "Epoch 14, Train Loss: 0.1306, Train Accuracy: 0.9608, Train Precision: 202/1229 (16%), Train Recall: 202/215 (94%), Train F1: 28%\n",
      "Epoch 14, Test Loss: 0.1805, Test Accuracy: 0.9714, Test Precision: 49/357 (14%), Test Recall: 49/67 (73%), Test F1: 23%\n",
      "Epoch 15, Train Loss: 0.1085, Train Accuracy: 0.9663, Train Precision: 202/1083 (19%), Train Recall: 202/215 (94%), Train F1: 31%\n",
      "Epoch 15, Test Loss: 0.1700, Test Accuracy: 0.9712, Test Precision: 51/363 (14%), Test Recall: 51/67 (76%), Test F1: 24%\n",
      "Epoch 16, Train Loss: 0.1025, Train Accuracy: 0.9693, Train Precision: 204/1007 (20%), Train Recall: 204/215 (95%), Train F1: 33%\n",
      "Epoch 16, Test Loss: 0.1563, Test Accuracy: 0.9713, Test Precision: 52/364 (14%), Test Recall: 52/67 (78%), Test F1: 24%\n",
      "Epoch 17, Train Loss: 0.0898, Train Accuracy: 0.9710, Train Precision: 205/966 (21%), Train Recall: 205/215 (95%), Train F1: 35%\n",
      "Epoch 17, Test Loss: 0.1458, Test Accuracy: 0.9723, Test Precision: 52/352 (15%), Test Recall: 52/67 (78%), Test F1: 25%\n",
      "Epoch 18, Train Loss: 0.0788, Train Accuracy: 0.9749, Train Precision: 211/874 (24%), Train Recall: 211/215 (98%), Train F1: 39%\n",
      "Epoch 18, Test Loss: 0.1341, Test Accuracy: 0.9729, Test Precision: 53/347 (15%), Test Recall: 53/67 (79%), Test F1: 26%\n",
      "Epoch 19, Train Loss: 0.0710, Train Accuracy: 0.9766, Train Precision: 210/826 (25%), Train Recall: 210/215 (98%), Train F1: 40%\n",
      "Epoch 19, Test Loss: 0.1210, Test Accuracy: 0.9757, Test Precision: 58/325 (18%), Test Recall: 58/67 (87%), Test F1: 30%\n",
      "Epoch 20, Train Loss: 0.0661, Train Accuracy: 0.9794, Train Precision: 209/751 (28%), Train Recall: 209/215 (97%), Train F1: 43%\n",
      "Epoch 20, Test Loss: 0.1105, Test Accuracy: 0.9757, Test Precision: 58/325 (18%), Test Recall: 58/67 (87%), Test F1: 30%\n",
      "Epoch 21, Train Loss: 0.0654, Train Accuracy: 0.9704, Train Precision: 215/1001 (21%), Train Recall: 215/215 (100%), Train F1: 35%\n",
      "Epoch 21, Test Loss: 0.0957, Test Accuracy: 0.9760, Test Precision: 60/326 (18%), Test Recall: 60/67 (90%), Test F1: 31%\n",
      "Epoch 22, Train Loss: 0.0525, Train Accuracy: 0.9830, Train Precision: 211/659 (32%), Train Recall: 211/215 (98%), Train F1: 48%\n",
      "Epoch 22, Test Loss: 0.0935, Test Accuracy: 0.9794, Test Precision: 59/285 (21%), Test Recall: 59/67 (88%), Test F1: 34%\n",
      "Epoch 23, Train Loss: 0.0498, Train Accuracy: 0.9846, Train Precision: 211/617 (34%), Train Recall: 211/215 (98%), Train F1: 51%\n",
      "Epoch 23, Test Loss: 0.0922, Test Accuracy: 0.9797, Test Precision: 60/284 (21%), Test Recall: 60/67 (90%), Test F1: 34%\n",
      "Epoch 24, Train Loss: 0.0504, Train Accuracy: 0.9843, Train Precision: 212/626 (34%), Train Recall: 212/215 (99%), Train F1: 50%\n",
      "Epoch 24, Test Loss: 0.0909, Test Accuracy: 0.9802, Test Precision: 60/278 (22%), Test Recall: 60/67 (90%), Test F1: 35%\n",
      "Epoch 25, Train Loss: 0.0485, Train Accuracy: 0.9844, Train Precision: 212/624 (34%), Train Recall: 212/215 (99%), Train F1: 51%\n",
      "Epoch 25, Test Loss: 0.0898, Test Accuracy: 0.9807, Test Precision: 60/273 (22%), Test Recall: 60/67 (90%), Test F1: 35%\n",
      "Epoch 26, Train Loss: 0.0458, Train Accuracy: 0.9847, Train Precision: 212/614 (35%), Train Recall: 212/215 (99%), Train F1: 51%\n",
      "Epoch 26, Test Loss: 0.0886, Test Accuracy: 0.9808, Test Precision: 60/272 (22%), Test Recall: 60/67 (90%), Test F1: 35%\n",
      "Epoch 27, Train Loss: 0.0477, Train Accuracy: 0.9851, Train Precision: 211/603 (35%), Train Recall: 211/215 (98%), Train F1: 52%\n",
      "Epoch 27, Test Loss: 0.0872, Test Accuracy: 0.9807, Test Precision: 60/273 (22%), Test Recall: 60/67 (90%), Test F1: 35%\n",
      "Epoch 28, Train Loss: 0.0443, Train Accuracy: 0.9852, Train Precision: 212/603 (35%), Train Recall: 212/215 (99%), Train F1: 52%\n",
      "Epoch 28, Test Loss: 0.0859, Test Accuracy: 0.9808, Test Precision: 60/272 (22%), Test Recall: 60/67 (90%), Test F1: 35%\n",
      "Epoch 29, Train Loss: 0.0439, Train Accuracy: 0.9847, Train Precision: 213/617 (35%), Train Recall: 213/215 (99%), Train F1: 51%\n",
      "Epoch 29, Test Loss: 0.0846, Test Accuracy: 0.9818, Test Precision: 60/260 (23%), Test Recall: 60/67 (90%), Test F1: 37%\n",
      "Epoch 30, Train Loss: 0.0447, Train Accuracy: 0.9858, Train Precision: 213/587 (36%), Train Recall: 213/215 (99%), Train F1: 53%\n",
      "Epoch 30, Test Loss: 0.0834, Test Accuracy: 0.9817, Test Precision: 60/261 (23%), Test Recall: 60/67 (90%), Test F1: 37%\n",
      "Epoch 31, Train Loss: 0.0422, Train Accuracy: 0.9856, Train Precision: 213/593 (36%), Train Recall: 213/215 (99%), Train F1: 53%\n",
      "Epoch 31, Test Loss: 0.0806, Test Accuracy: 0.9801, Test Precision: 62/284 (22%), Test Recall: 62/67 (93%), Test F1: 35%\n",
      "Epoch 32, Train Loss: 0.0438, Train Accuracy: 0.9860, Train Precision: 213/584 (36%), Train Recall: 213/215 (99%), Train F1: 53%\n",
      "Epoch 32, Test Loss: 0.0805, Test Accuracy: 0.9801, Test Precision: 62/284 (22%), Test Recall: 62/67 (93%), Test F1: 35%\n",
      "Epoch 33, Train Loss: 0.0421, Train Accuracy: 0.9861, Train Precision: 213/581 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 33, Test Loss: 0.0805, Test Accuracy: 0.9803, Test Precision: 62/281 (22%), Test Recall: 62/67 (93%), Test F1: 36%\n",
      "Epoch 34, Train Loss: 0.0411, Train Accuracy: 0.9863, Train Precision: 213/576 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 34, Test Loss: 0.0804, Test Accuracy: 0.9808, Test Precision: 62/276 (22%), Test Recall: 62/67 (93%), Test F1: 36%\n",
      "Epoch 35, Train Loss: 0.0418, Train Accuracy: 0.9863, Train Precision: 213/575 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 35, Test Loss: 0.0804, Test Accuracy: 0.9811, Test Precision: 62/272 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 36, Train Loss: 0.0417, Train Accuracy: 0.9864, Train Precision: 213/573 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 36, Test Loss: 0.0803, Test Accuracy: 0.9811, Test Precision: 62/272 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 37, Train Loss: 0.0427, Train Accuracy: 0.9864, Train Precision: 213/572 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 37, Test Loss: 0.0802, Test Accuracy: 0.9815, Test Precision: 62/268 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 38, Train Loss: 0.0408, Train Accuracy: 0.9864, Train Precision: 213/572 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 38, Test Loss: 0.0801, Test Accuracy: 0.9816, Test Precision: 62/266 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 39, Train Loss: 0.0419, Train Accuracy: 0.9865, Train Precision: 213/570 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 39, Test Loss: 0.0800, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 40, Train Loss: 0.0422, Train Accuracy: 0.9865, Train Precision: 213/570 (37%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 40, Test Loss: 0.0799, Test Accuracy: 0.9818, Test Precision: 62/264 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 41, Train Loss: 0.0421, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 41, Test Loss: 0.0796, Test Accuracy: 0.9815, Test Precision: 62/268 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 42, Train Loss: 0.0426, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 42, Test Loss: 0.0796, Test Accuracy: 0.9815, Test Precision: 62/267 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 43, Train Loss: 0.0407, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 43, Test Loss: 0.0795, Test Accuracy: 0.9815, Test Precision: 62/267 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 44, Train Loss: 0.0414, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 44, Test Loss: 0.0795, Test Accuracy: 0.9816, Test Precision: 62/266 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 45, Train Loss: 0.0415, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 45, Test Loss: 0.0795, Test Accuracy: 0.9816, Test Precision: 62/266 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 46, Train Loss: 0.0410, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 46, Test Loss: 0.0795, Test Accuracy: 0.9816, Test Precision: 62/266 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 47, Train Loss: 0.0417, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 47, Test Loss: 0.0795, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 48, Train Loss: 0.0406, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 48, Test Loss: 0.0795, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 49, Train Loss: 0.0407, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 49, Test Loss: 0.0795, Test Accuracy: 0.9818, Test Precision: 62/264 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 50, Train Loss: 0.0417, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 50, Test Loss: 0.0795, Test Accuracy: 0.9818, Test Precision: 62/264 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 51, Train Loss: 0.0405, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 51, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 52, Train Loss: 0.0397, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 52, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 53, Train Loss: 0.0422, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 53, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 54, Train Loss: 0.0425, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 54, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 55, Train Loss: 0.0415, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 55, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 56, Train Loss: 0.0419, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 56, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 57, Train Loss: 0.0400, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 57, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 58, Train Loss: 0.0425, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 58, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 59, Train Loss: 0.0401, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 59, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 60, Train Loss: 0.0411, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 60, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 61, Train Loss: 0.0427, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 61, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 62, Train Loss: 0.0417, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 62, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 63, Train Loss: 0.0420, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 63, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 64, Train Loss: 0.0404, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 64, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 65, Train Loss: 0.0401, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 65, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 66, Train Loss: 0.0410, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 66, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 67, Train Loss: 0.0412, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 67, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 68, Train Loss: 0.0425, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 68, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 69, Train Loss: 0.0431, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 69, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n",
      "Epoch 70, Train Loss: 0.0430, Train Accuracy: 0.9866, Train Precision: 213/567 (38%), Train Recall: 213/215 (99%), Train F1: 54%\n",
      "Epoch 70, Test Loss: 0.0794, Test Accuracy: 0.9817, Test Precision: 62/265 (23%), Test Recall: 62/67 (93%), Test F1: 37%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     savedStdout = sys.stdout  #保存标准输出流\n",
    "#     f = open(log_out, 'a') \n",
    "#     sys.stdout = f  #输出流变成文件\n",
    "    for m in range(1):\n",
    "#         model = model_list[m]\n",
    "        if str(server) == \"76\":\n",
    "            model = nn.DataParallel(model,device_ids=[0,1])\n",
    "        lr = args.lr\n",
    "        optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "        acc_list_train,acc_list_test,pre_train,pre_test,re_train,re_test,f1_train,f1_test = [],[],[],[],[],[],[],[]\n",
    "        loss_train,loss_test = [],[]\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train(train_loader,model,epoch)\n",
    "            test(test_loader,model,epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                lr /= 10\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "        # 保存整个网络\n",
    "#         torch.save(model,model_save+\"imvtcn_model_\"+model_index[m]+\".pt\") \n",
    "#         # 保存网络中的参数, 速度快，占空间少\n",
    "#         torch.save(model.state_dict(),model_save+\"imvtcn_hyperparam_\"+model_index[m]+\".pt\")\n",
    "#         outdf = pd.DataFrame({\"Acc_train\":acc_list_train,\"Acc_test\":acc_list_test,\"Pre_train\":pre_train,\"Pre_test\":pre_test,\n",
    "#                      \"Recall_train\":re_train,\"Recall_test\":re_test,\"F1_train\":f1_train,\"F1_test\":f1_test,\"loss_train\":loss_train,\n",
    "#                              \"loss_test\":loss_test})\n",
    "#         outdf.to_csv(model_save+\"evaluate_imvtcn_\"+model_index[m]+\".csv\",index = False)\n",
    "        torch.cuda.empty_cache()\n",
    "#     sys.stdout = savedStdout  #恢复标准输出流\n",
    "#     print ('已输出结果，恢复标准输出流!')\n",
    "#     f.close() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMVTCN(\n",
       "  (net1): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (4): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (5): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (6): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (7): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (8): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (9): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (10): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (11): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (12): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (13): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (14): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (15): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (16): Linear(in_features=30, out_features=30, bias=True)\n",
       "  )\n",
       "  (net2): ModuleList(\n",
       "    (0): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (1): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (net4): ModuleList(\n",
       "    (0): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (1): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (2): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (3): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (4): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (5): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (net8): ModuleList(\n",
       "    (0): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "    (1): GRU(\n",
       "      (gru_cell): GRUCell(30, 30)\n",
       "      (linear): Linear(in_features=30, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear1): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (8): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (9): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (10): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (11): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (12): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (13): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (14): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (15): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (16): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear2): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear4): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear8): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (linear): Linear(in_features=27, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSAD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
